{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## This is the new method"
      ],
      "metadata": {
        "id": "87oJtRHiDLIb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers sentence-transformers faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "a7i9njjPCTvg",
        "outputId": "05cc9c14-ffd9-4ea0-9171-bfef87a92bac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.3.1)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.9.0.post1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (11.0.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import faiss\n",
        "import torch"
      ],
      "metadata": {
        "id": "S8KVhXpADTAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedder = SentenceTransformer('all-MiniLM-L6-v2')"
      ],
      "metadata": {
        "id": "9BPOyx-XDXav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('document1.txt', 'r') as f:\n",
        "    document_text = f.read()"
      ],
      "metadata": {
        "id": "D6PXfGOFEJky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "document_chunks = document_text.split('.')\n",
        "\n",
        "# Generate embeddings for the document chunks\n",
        "document_embeddings = embedder.encode(document_chunks)\n",
        "\n",
        "# Create a FAISS index\n",
        "index = faiss.IndexFlatL2(document_embeddings.shape[1])\n",
        "index.add(document_embeddings)"
      ],
      "metadata": {
        "id": "-OdlIh57ENN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "we0wSJTgETHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(query, retrieved_documents):\n",
        "    \"\"\"Generates a response using the LLM.\"\"\"\n",
        "    input_ids = tokenizer(query, return_tensors=\"pt\").input_ids\n",
        "    attention_mask = tokenizer(query, return_tensors=\"pt\").attention_mask\n",
        "\n",
        "    #Concatenate retrieved documents with query\n",
        "    input_text = query + \" \".join(retrieved_documents)\n",
        "    input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
        "    attention_mask = tokenizer(input_text, return_tensors=\"pt\").attention_mask\n",
        "\n",
        "    output = model.generate(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        max_length=128,\n",
        "    )\n",
        "\n",
        "    return tokenizer.decode(output[0], skip_special_tokens=True)\n"
      ],
      "metadata": {
        "id": "lVDpD3rKEXRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    query = input(\"Enter your query: \")\n",
        "    if query.lower() == 'thank you':\n",
        "        break\n",
        "\n",
        "    # Generate an embedding for the query\n",
        "    query_embedding = embedder.encode([query])[0]\n",
        "\n",
        "    # Find the most similar documents\n",
        "    k = 2  # Number of nearest neighbors\n",
        "    distances, indices = index.search(query_embedding.reshape(1, -1), k)\n",
        "\n",
        "    # Retrieve the relevant document chunks\n",
        "    retrieved_documents = [document_chunks[i] for i in indices[0]]\n",
        "\n",
        "    # Generate the response\n",
        "    response = generate_response(query, retrieved_documents)\n",
        "\n",
        "    print(\"Response:\", response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcUWtKWCEgx4",
        "outputId": "544c5d45-dc0d-4fd5-cc43-c392e0643474"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your query: what is the document about\n",
            "Response: Supervised Learning\n",
            "Enter your query: explain eerything present in the document\n",
            "Response: Unsupervised Learning: The model identifies patterns in data without labels Reinforcement Learning: The model learns by interacting with the environment and receiving feedback in the form of rewards or penalties.\n",
            "Enter your query: I dont understand Reinforcement Learning\n",
            "Response: I dont understand Reinforcement Learning Reinforcement Learning: The model learns by interacting with the environment and receiving feedback in the form of rewards or penalties Machine learning is a subset of artificial intelligence (AI) that involves the use of algorithms and statistical models to perform tasks without explicitly programmed instructions\n",
            "Enter your query: explain reinforcement learning\n",
            "Response: Reinforcement learning is a subset of artificial intelligence (AI) that involves the use of algorithms and statistical models to perform tasks without explicitly programmed instructions.\n",
            "Enter your query: thank you\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UG21UtYZElzp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}